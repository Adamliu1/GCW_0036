{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256a7c25",
   "metadata": {},
   "source": [
    "# COMP0036 Group Assignment: BEAT THE BOOKIE\n",
    "\n",
    "### Group N\n",
    "\n",
    "We have been assigned to build model(s) that predict the FTR value, which can be Home Win (H), Draw (D) and Away Win (A). The general steps we will be taking to build the model(s) begins with finding a suitable dataset and performing feature engineering on the selected features to be used in the model. This entails creating functions or classes to convert the raw data and transforms it into a format where every match has that historic feature. Then, we perform feature selection to filter out unimportant features, and use the selected features in model(s), and then compare and decide the best performing model. Finally, improve models to get the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e403d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c251fecf",
   "metadata": {},
   "source": [
    "Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e99ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.path.join(os.getcwd(), 'Group Coursework Brief-20221106', 'Data_Files', 'Data_Files')\n",
    "dirName_trainData = os.path.join(cwd, 'epl-full-training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822318ab",
   "metadata": {},
   "source": [
    "## Data Analysis \n",
    "\n",
    "#### AIM:\n",
    "\n",
    "- Given match date, Filter the dataframe for the all games of current year\n",
    "\n",
    "- Given HomeTeam & AwayTeam, Filter database for all games (in this time frame) where HomeTeam is Home against all other teams, same for AwayTeam => Return two filtered dataframes\n",
    "\n",
    "- Average these past stats for the home and away teams from current and last season\n",
    "\n",
    "- Give the home and away teams ratings based upon the weighted sum of the past stats\n",
    "\n",
    "- Create a expected goals predictor using linear/polynomial regression using the past average stats\n",
    "\n",
    "- Final Classifier takes as input: Home and Away Team ratings, expected goals, day, month, hometeam and awayteam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc571ddf",
   "metadata": {},
   "source": [
    "Data was obtained from football-data.co.uk, where we used historical data from the 2000-2001 seeason till the current year as it was the most consistent and robust data files. The list below shows the features obtained from the data files and their meanings.\n",
    "\n",
    "Div = League Division \n",
    "\n",
    "Date = Match Date (dd/mm/yy)\n",
    "\n",
    "HomeTeam = Home Team\n",
    "\n",
    "AwayTeam = Away Team\n",
    "\n",
    "FTHG = Full Time Home Team Goals\n",
    "\n",
    "FTAG = Full Time Away Team Goals\n",
    "\n",
    "FTR = Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "\n",
    "HTHG = Half Time Home Team Goals\n",
    "\n",
    "HTAG = Half Time Away Team Goals\n",
    "\n",
    "HTR = Half Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "\n",
    "HS = Home Team Shots\n",
    "\n",
    "AS = Away Team Shots\n",
    "\n",
    "HST = Home Team Shots on Target\n",
    "\n",
    "AST = Away Team Shots on Target\n",
    "\n",
    "HF = Home Team Fouls Committed\n",
    "\n",
    "AF = Away Team Fouls Committed\n",
    "\n",
    "HC = Home Team Corners\n",
    "\n",
    "AC = Away Team Corners\n",
    "\n",
    "HY = Home Team Yellow Cards\n",
    "\n",
    "AY = Away Team Yellow Cards\n",
    "\n",
    "HR = Home Team Red Cards\n",
    "\n",
    "AR = Away Team Red Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1639105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epl_train = pd.read_csv(dirName_trainData)\n",
    "cols = [\"Div\",\"Date\",\"HomeTeam\",\"AwayTeam\",\"FTHG\", \"FTAG\",\"FTR\",\"HTHG\",\"HTAG\",\"HTR\",\"HS\",\"AS\", \"HST\",\"AST\",\"HF\",\"AF\",\"HC\",\"AC\",\"HY\",\"AY\",\"HR\",\"AR\"]\n",
    "\n",
    "df_epl_train = df_epl_train.loc[:, cols]\n",
    "df_epl_train = df_epl_train.reset_index(drop=True)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(df_epl_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d88b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the date column from strings into datetime objects\n",
    "df_epl_train[\"Date\"] = pd.to_datetime(df_epl_train[\"Date\"], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epl_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc17c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will take as input a date, HomeTeam and AwayTeam and output two filtered dataframe\n",
    "\n",
    "def get_season_start_date(date):\n",
    "    if date.month <= 7:\n",
    "        return datetime(date.year-1, 8, 1)\n",
    "    return datetime(date.year, 8, 1)\n",
    "\n",
    "def filter_dataframe_by_hometeam_recent_season(df, date, HomeTeam):\n",
    "    # Convert the input string date into datetime\n",
    "    date = pd.to_datetime(date, dayfirst=True)\n",
    "\n",
    "    # Filter the dataframe to include only rows where Dateinput(first day of season) && HomeTeam=input(HomeTeam)\n",
    "    df_filtered = df.copy()\n",
    "    df_filtered = df_filtered[(df_filtered.Date<date) & (df_filtered.Date>get_season_start_date(date)) & (df_filtered.HomeTeam==HomeTeam)]\n",
    "\n",
    "    # Return filtered dataframe\n",
    "    return df_filtered\n",
    "\n",
    "def filter_dataframe_by_awayteam_recent_season(df, date, AwayTeam):\n",
    "    # Convert the input string date into datetime\n",
    "    date = pd.to_datetime(date, dayfirst=True)\n",
    "\n",
    "    # Filter the dataframe to include only rows where Dateinput(first day of season) && HomeTeam=input(HomeTeam)\n",
    "    df_filtered = df.copy()\n",
    "    df_filtered = df_filtered[(df_filtered.Date<date) & (df_filtered.Date>get_season_start_date(date)) & (df_filtered.AwayTeam==AwayTeam)]\n",
    "\n",
    "    # Return filtered dataframe\n",
    "    return df_filtered\n",
    "\n",
    "# For Example:\n",
    "# date = \"24/06/2020\"\n",
    "# HomeTeam = \"Newcastle\"\n",
    "# AwayTeam = \"Aston Villa\"\n",
    "\n",
    "# An example to see what the function does:\n",
    "df_epl_train_filtered_Home = filter_dataframe_by_hometeam_recent_season(df_epl_train, \"24/06/2020\", \"Newcastle\")\n",
    "df_epl_train_filtered_Away = filter_dataframe_by_awayteam_recent_season(df_epl_train, \"24/06/2020\", \"Aston Villa\")\n",
    "print(df_epl_train_filtered_Home)\n",
    "print(df_epl_train_filtered_Away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc448a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes as input a filtered dataframe from previous cell, features to average and a dictionary,\n",
    "# it then appends an average of each feature to the dictionary\n",
    "\n",
    "def average_columns(features, avg_features, filtered_df):\n",
    "    for feature in features:\n",
    "        df_col_means = filtered_df[feature].mean()\n",
    "        avg_features[feature].append(df_col_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the two functions for each row of our df_epl_train dataframe to fill dictionary with AVG for each match\n",
    "# NOTE: Some matches won't have past stats since its the first game of the season or we might not have past data\n",
    "\n",
    "features = [\"FTHG\",\"FTAG\",\"HTHG\",\"HTAG\",\"HS\",\"AS\",\"HST\",\"AST\",\"HF\",\"AF\",\"HC\",\"AC\",\"HY\",\"AY\",\"HR\",\"AR\"]\n",
    "avg_features_HOME = {\n",
    "                        \"FTHG\": [],\n",
    "                        \"FTAG\": [],\n",
    "                        \"HTHG\": [],\n",
    "                        \"HTAG\": [],\n",
    "                        \"HS\"  : [],\n",
    "                        \"AS\"  : [],\n",
    "                        \"HST\" : [],\n",
    "                        \"AST\" : [],\n",
    "                        \"HF\"  : [],\n",
    "                        \"AF\"  : [],\n",
    "                        \"HC\"  : [],\n",
    "                        \"AC\"  : [],\n",
    "                        \"HY\"  : [],\n",
    "                        \"AY\"  : [],\n",
    "                        \"HR\"  : [],\n",
    "                        \"AR\"  : []\n",
    "                    }\n",
    "\n",
    "avg_features_AWAY = {\n",
    "                        \"FTHG\": [],\n",
    "                        \"FTAG\": [],\n",
    "                        \"HTHG\": [],\n",
    "                        \"HTAG\": [],\n",
    "                        \"HS\"  : [],\n",
    "                        \"AS\"  : [],\n",
    "                        \"HST\" : [],\n",
    "                        \"AST\" : [],\n",
    "                        \"HF\"  : [],\n",
    "                        \"AF\"  : [],\n",
    "                        \"HC\"  : [],\n",
    "                        \"AC\"  : [],\n",
    "                        \"HY\"  : [],\n",
    "                        \"AY\"  : [],\n",
    "                        \"HR\"  : [],\n",
    "                        \"AR\"  : []\n",
    "                    }\n",
    "\n",
    "# Run the two functions on each row of the df_epl_train and fill the dictionary\n",
    "# We need to do this for the HOME filtered dataframe, and AWAY filtered dataframe\n",
    "\n",
    "# For each row in our original dataframe\n",
    "for index, row in df_epl_train.iterrows():\n",
    "    # Filter the dataframe to only show matches played between those teams and before the certain date\n",
    "    df_epl_train_filtered_Home = filter_dataframe_by_hometeam_recent_season(df_epl_train, row[\"Date\"],row[\"HomeTeam\"])\n",
    "    df_epl_train_filtered_Away = filter_dataframe_by_awayteam_recent_season(df_epl_train, row[\"Date\"],row[\"AwayTeam\"])\n",
    "    # Get averages from the filtered dataframe and add the the dictionary\n",
    "    average_columns(features, avg_features_HOME, df_epl_train_filtered_Home)\n",
    "    average_columns(features, avg_features_AWAY, df_epl_train_filtered_Away)\n",
    "    \n",
    "# Check this is correct\n",
    "# print(avg_features_HOME)\n",
    "# print(avg_features_AWAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for each of these feature averages using the list of values from the dictionary\n",
    "df_epl_train_updated = df_epl_train.copy()\n",
    "features = [\"FTHG\",\"FTAG\",\"HTHG\",\"HTAG\",\"HS\",\"AS\",\"HST\",\"AST\",\"HF\",\"AF\",\"HC\",\"AC\",\"HY\",\"AY\",\"HR\",\"AR\"]\n",
    "\n",
    "for feature in features:\n",
    "    # Get the list of averages for a certain feature from the dicitonary\n",
    "    feature_vals_HOME = avg_features_HOME[feature]\n",
    "    feature_vals_AWAY = avg_features_AWAY[feature]\n",
    "    # Add the list of averages into the dataframe for that certain feature\n",
    "    df_epl_train_updated[feature + \"_AVG_Home\"] = feature_vals_HOME\n",
    "    df_epl_train_updated[feature + \"_AVG_Away\"] = feature_vals_AWAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc900d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now this dataframe contains our original data + the average of the past stats (Home & Away) for each row\n",
    "df_epl_train_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e6085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we loop through the updated dataframe and for each row average the HomeAvgStats and AwayAvgStats using \n",
    "# weights to give higher importance to some specific stats. This results in creating and adding two final columns.\n",
    "\n",
    "features = [\"FTHG\",\"FTAG\",\"HTHG\",\"HTAG\",\"HS\",\"AS\",\"HST\",\"AST\",\"HF\",\"AF\",\"HC\",\"AC\",\"HY\",\"AY\",\"HR\",\"AR\"]\n",
    "feature_weights = {\n",
    "                        \"FTHG\": 0,\n",
    "                        \"FTAG\": 0,\n",
    "                        \"HTHG\": 0,\n",
    "                        \"HTAG\": 0,\n",
    "                        \"HS\"  : 2,\n",
    "                        \"AS\"  : 2,\n",
    "                        \"HST\" : 2.5,\n",
    "                        \"AST\" : 2.5,\n",
    "                        \"HF\"  : 1.5,\n",
    "                        \"AF\"  : 1.5,\n",
    "                        \"HC\"  : 0.5,\n",
    "                        \"AC\"  : 0.5,\n",
    "                        \"HY\"  : 0.5,\n",
    "                        \"AY\"  : 0.5,\n",
    "                        \"HR\"  : 0.5,\n",
    "                        \"AR\"  : 0.5\n",
    "                    }\n",
    "    \n",
    "Home_Weighted_Avg = []\n",
    "Away_Weighted_Avg = []\n",
    "\n",
    "for index, row in df_epl_train_updated.iterrows():\n",
    "    home_vals = []\n",
    "    away_vals = []\n",
    "    for feature in features:\n",
    "        current_feature_HOME = feature + \"_AVG_Home\"\n",
    "        current_feature_AWAY = feature + \"_AVG_Away\"\n",
    "        current_val_HOME = row[current_feature_HOME]*feature_weights[feature]\n",
    "        current_val_AWAY = row[current_feature_AWAY]*feature_weights[feature]\n",
    "        home_vals.append(current_val_HOME)\n",
    "        away_vals.append(current_val_AWAY)\n",
    "    Home_Weighted_Avg.append(sum(home_vals)/len(home_vals))\n",
    "    Away_Weighted_Avg.append(sum(away_vals)/len(away_vals))\n",
    "\n",
    "df_epl_train_final = df_epl_train.copy()\n",
    "df_epl_train_final[\"HomeTeam_Rating\"] = Home_Weighted_Avg\n",
    "df_epl_train_final[\"AwayTeam_Rating\"] = Away_Weighted_Avg\n",
    "\n",
    "# Check if its working correctly\n",
    "df_epl_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab2db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the catergorical data into labels using same method from before\n",
    "df_epl_train_final[\"AwayTeam_Enc\"] = df_epl_train_final[\"AwayTeam\"].astype(\"category\").cat.codes\n",
    "df_epl_train_final[\"HomeTeam_Enc\"] = df_epl_train_final[\"HomeTeam\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Transform the date column into day and month columns and Add into dataframe (Extract days & months from date)\n",
    "df_epl_train_final[\"Date\"] = pd.to_datetime(df_epl_train_final[\"Date\"])\n",
    "df_epl_train_final[\"Day\"] = df_epl_train_final[\"Date\"].dt.day\n",
    "df_epl_train_final[\"Month\"] = df_epl_train_final[\"Date\"].dt.month \n",
    "df_epl_train_final[\"Year\"] = df_epl_train_final[\"Date\"].dt.year\n",
    "\n",
    "# Add average values from updated dataframe\n",
    "df_epl_train_final[\"FTHG_AVG\"] = df_epl_train_updated[\"FTHG_AVG_Home\"]\n",
    "df_epl_train_final[\"FTAG_AVG\"] = df_epl_train_updated[\"FTAG_AVG_Away\"]\n",
    "df_epl_train_final[\"HTHG_AVG\"] = df_epl_train_updated[\"HTHG_AVG_Home\"]\n",
    "df_epl_train_final[\"HTAG_AVG\"] = df_epl_train_updated[\"HTAG_AVG_Away\"]\n",
    "df_epl_train_final[\"HS_AVG\"] = df_epl_train_updated[\"HS_AVG_Home\"]\n",
    "df_epl_train_final[\"AS_AVG\"] = df_epl_train_updated[\"AS_AVG_Away\"]\n",
    "df_epl_train_final[\"HST_AVG\"] = df_epl_train_updated[\"HST_AVG_Home\"]\n",
    "df_epl_train_final[\"AST_AVG\"] = df_epl_train_updated[\"AST_AVG_Away\"]\n",
    "df_epl_train_final[\"HF_AVG\"] = df_epl_train_updated[\"HF_AVG_Home\"]\n",
    "df_epl_train_final[\"AF_AVG\"] = df_epl_train_updated[\"AF_AVG_Away\"]\n",
    "df_epl_train_final[\"HC_AVG\"] = df_epl_train_updated[\"HC_AVG_Home\"]\n",
    "df_epl_train_final[\"AC_AVG\"] = df_epl_train_updated[\"AC_AVG_Away\"]\n",
    "df_epl_train_final[\"HY_AVG\"] = df_epl_train_updated[\"HY_AVG_Home\"]\n",
    "df_epl_train_final[\"AY_AVG\"] = df_epl_train_updated[\"AY_AVG_Away\"]\n",
    "df_epl_train_final[\"HR_AVG\"] = df_epl_train_updated[\"HR_AVG_Home\"]\n",
    "df_epl_train_final[\"AR_AVG\"] = df_epl_train_updated[\"AR_AVG_Away\"]\n",
    "\n",
    "# Check the final updated dataframe\n",
    "df_epl_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ab63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We must remove the rows in the dataframe where the average values of stats/features are 'nan';\n",
    "# we get these values because either its the teams first game of the season OR because we have\n",
    "# not got the past stats for these matches. We cannot use the 'nan' values for the classifier training and \n",
    "# hence have to remove these rows. We can then train a classifier using this final dataframe.\n",
    "\n",
    "# In the final model/classifier, in the case where we DO NOT have these past stats of the teams playing, \n",
    "# we need to switch back to using the OLD classifier which only took the 4 basic fetaures: day, month, \n",
    "# HomeTeam and AwayTeam.\n",
    "\n",
    "# In the case where we DO have these past stats for the teams, we can use this model/classifier \n",
    "# and input the features like HST_AVG. We would find these by using the filter_dataframe() and \n",
    "# average_columns() functions to find them for any two specific teams playing each other on some date.\n",
    "\n",
    "# Remove any rows with nan\n",
    "df_epl_train_final = df_epl_train_final.dropna()\n",
    "df_epl_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b7f84f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06872493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51911f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140eb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f63f264",
   "metadata": {},
   "source": [
    "## Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da245bd",
   "metadata": {},
   "source": [
    "### 1. Random Guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b35a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb18331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acd56c00",
   "metadata": {},
   "source": [
    "### 2. Home Team, Away Team & FTR Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da2c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa82628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4f386aa",
   "metadata": {},
   "source": [
    "### 3. Add DateTime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff3dca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac388846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7725992",
   "metadata": {},
   "source": [
    "###  4. Add average between two specific teams for all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dadd119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b265d2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53770bbc",
   "metadata": {},
   "source": [
    "### 5. Average of single team over one season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ba8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a407dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "771f8a8e",
   "metadata": {},
   "source": [
    "### 6. Added team ratings, Added expected goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e363167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de561c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ac55e2e",
   "metadata": {},
   "source": [
    "## Classifier models:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0bbefd",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e24ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try either using polynomial regression, NN or more features, the MSE is too high with linear regression and current features\n",
    "\n",
    "# Here we aim to create a 'expected or predicted goals for a HomeTeam' feature based upon the HomeTeamRating, and also the past wins, losses and draws, our outputs will be full time goals(FTHG).\n",
    "X2 = df_epl_train_final.loc[:,['Day', 'Month', 'HomeTeam_Enc', 'FTHG_AVG', 'HTHG_AVG', 'HS_AVG', 'HomeTeam_Rating']].values\n",
    "y2 = df_epl_train_final.loc[:,'FTHG'].values\n",
    "# Split the data for testing\n",
    "X2_train, X2_test, y2_train, y2_test = model_selection.train_test_split(X2, y2, test_size=0.2, random_state=20)\n",
    "# Here we use a linear regression classifier to predict the goals BUT could use a polynomial regression classifier:\n",
    "# Create an empty linear regression model\n",
    "LR_Model_HOME_EG = LinearRegression()\n",
    "# Fit the model using training data\n",
    "LR_Model_HOME_EG.fit(X2_train, y2_train)\n",
    "# Make predictions using the model we have created\n",
    "LR_H_predictions_test = LR_Model_HOME_EG.predict(X2_test)\n",
    "\n",
    "\n",
    "# Similar idea for AwayTeam\n",
    "X3 = df_epl_train_final.loc[:,['Day', 'Month', 'AwayTeam_Enc', 'FTAG_AVG', 'HTAG_AVG', 'AS_AVG', 'AwayTeam_Rating']].values\n",
    "y3 = df_epl_train_final.loc[:,'FTAG'].values\n",
    "# Split the data for testing\n",
    "X3_train, X3_test, y3_train, y3_test = model_selection.train_test_split(X3, y3, test_size=0.2, random_state=20)\n",
    "LR_Model_AWAY_EG = LinearRegression()\n",
    "# Fit the model using training data\n",
    "LR_Model_AWAY_EG.fit(X3_train, y3_train)\n",
    "# Make predictions using the model we have created\n",
    "LR_A_predictions_test = LR_Model_AWAY_EG.predict(X3_test)\n",
    "\n",
    "\n",
    "# Check the mean square error(MSE) for HomeTeam Expected Goals\n",
    "print(mean_squared_error(LR_H_predictions_test, y2_test))\n",
    "# Check the mean square error(MSE) for AwayTeam Expected Goals\n",
    "print(mean_squared_error(LR_A_predictions_test, y3_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef539dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the two regression classfiers above, predict the number of goals that the Home and Away teams will hit for each row in the dataframe:\n",
    "HomeExGoals = []\n",
    "AwayExGoals = []\n",
    "# For each row, predict the home and away expected goals\n",
    "for index, row in df_epl_train_final.iterrows():\n",
    "    X_Home_features = np.array([[row[\"Day\"],row[\"Month\"],row[\"HomeTeam_Enc\"],row[\"FTHG_AVG\"],row[\"HTHG_AVG\"],row[\"HS_AVG\"],row[\"HomeTeam_Rating\"]]])\n",
    "    X_Away_features = np.array([[row[\"Day\"],row[\"Month\"],row[\"AwayTeam_Enc\"],row[\"FTAG_AVG\"],row[\"HTAG_AVG\"],row[\"AS_AVG\"],row[\"AwayTeam_Rating\"]]])\n",
    "    # Note the prediction is a 1 by 1 vector\n",
    "    ex_home_goals = LR_Model_HOME_EG.predict(X_Home_features)[0]\n",
    "    ex_away_goals = LR_Model_AWAY_EG.predict(X_Away_features)[0]\n",
    "    HomeExGoals.append(ex_home_goals)\n",
    "    AwayExGoals.append(ex_away_goals)\n",
    "\n",
    "# Add this data into the final dataframe\n",
    "df_epl_train_final[\"Ex_Goals_Home\"] = HomeExGoals\n",
    "df_epl_train_final[\"Ex_Goals_Away\"] = AwayExGoals\n",
    "\n",
    "# Check the final dataframe\n",
    "df_epl_train_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2976dcf3",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975fcf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty Random Forest model\n",
    "RF_Model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "# Fit the model using training data\n",
    "RF_Model.fit(X_train, y_train)\n",
    "# Make predictions using the model we have created\n",
    "RF_predictions_test = RF_Model.predict(X_test)\n",
    "RF_predictions_test = FTR_encoder.inverse_transform(RF_predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd046e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(RF_predictions_test, y_test))\n",
    "print(classification_report(RF_predictions_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2600ca90",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647f2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4c563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ee5de7f",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd08994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty Tree model\n",
    "DT_Model = DecisionTreeClassifier(random_state=42)\n",
    "# Fit the model using training data\n",
    "DT_Model.fit(X_train, y_train)\n",
    "# Make predictions using the model we have created\n",
    "DT_predictions_test = DT_Model.predict(X_test)\n",
    "# Reconverting prediction values (i.e. 0, 1 or 2) back into (H, D or A) using the FTR_encoder defined in earlier cell\n",
    "DT_predictions_test = FTR_encoder.inverse_transform(DT_predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a19a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(DT_predictions_test, y_test))\n",
    "print(classification_report(DT_predictions_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6301a0",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773bfe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty KNN model\n",
    "KNN_Model = KNeighborsClassifier(n_neighbors=6)\n",
    "# Fit the model using training data\n",
    "KNN_Model.fit(X_train, y_train)\n",
    "# Make predictions using the model we have created\n",
    "KNN_predictions_test = KNN_Model.predict(X_test)\n",
    "KNN_predictions_test = FTR_encoder.inverse_transform(KNN_predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d64b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(KNN_predictions_test, y_test))\n",
    "print(classification_report(KNN_predictions_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38abf34",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a7f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators=100, max_depth=100, random_state=42)\n",
    "xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e00ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = xgb.predict(x_test)\n",
    "print(\"Accuracy\", accuracy_score(y_test, y_preds))\n",
    "plot_confusion_matrix(xgb, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c790ee",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39165410",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(X.shape[1], activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cbaea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac1e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NN Resullt\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd11c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix(\n",
    "        y_test,\n",
    "        tf.argmax(model.predict(x_test), axis=1)\n",
    "    )\n",
    ").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebdba51",
   "metadata": {},
   "source": [
    "## Results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd8cc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5ed0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129aa47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('COMP0036')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "17969e96c672e81b7c4af3859a4ff591d8f1fed8af1fa4f38310cd48afd8d95b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
